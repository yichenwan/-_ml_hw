{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2: Phoneme Classification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "* Solve a classification problem with deep neural networks (DNNs).\n",
        "* Understand recursive neural networks (RNNs).\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ],
      "metadata": {
        "id": "A7DRC5V7_8A5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "# Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`: training metadata\n",
        "- `libriphone/train_labels`: training labels\n",
        "- `libriphone/test_split.txt`: testing metadata\n",
        "- `libriphone/feat/train/*.pt`: training feature\n",
        "- `libriphone/feat/test/*.pt`:  testing feature\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OzkiMEcC3Foq",
        "outputId": "53d4a631-a265-400d-a8a5-020eda764877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1\n",
            "From (redirected): https://drive.google.com/uc?id=1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1&confirm=t&uuid=71416c62-b2d1-4a47-9a47-d36dfeb93fb3\n",
            "To: /content/libriphone.zip\n",
            "100% 384M/384M [00:06<00:00, 61.4MB/s]\n",
            "feat  test_split.txt  train_labels.txt\ttrain_split.txt\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gdown\n",
        "\n",
        "# Main link\n",
        "# !gdown --id '1N1eVIDe9hKM5uiNRGmifBlwSDGiVXPJe' --output libriphone.zip\n",
        "!gdown --id '1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1' --output libriphone.zip\n",
        "\n",
        "!unzip -q libriphone.zip\n",
        "!ls libriphone"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Utility Functions\n",
        "**Fixes random number generator seeds for reproducibility.**"
      ],
      "metadata": {
        "id": "pADUiYODJE1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "BsZKgBZQJjaE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IJjLT8em-y9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n)\n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n",
        "    class_num = 41 # NOTE: pre-computed, should not need change\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        mode = 'train'\n",
        "    elif split == 'test':\n",
        "        mode = 'test'\n",
        "    else:\n",
        "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode == 'train':\n",
        "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.seed(random_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        train_len = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "\n",
        "    elif mode == 'test':\n",
        "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    max_len = 3000000\n",
        "    X = torch.empty(max_len, 39 * concat_nframes)\n",
        "    if mode == 'train':\n",
        "        y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        feat = concat_feat(feat, concat_nframes)\n",
        "        if mode == 'train':\n",
        "          label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "        X[idx: idx + cur_len, :] = feat\n",
        "        if mode == 'train':\n",
        "          y[idx: idx + cur_len] = label\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    X = X[:idx, :]\n",
        "    if mode == 'train':\n",
        "      y = y[:idx]\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(X.shape)\n",
        "    if mode == 'train':\n",
        "      print(y.shape)\n",
        "      return X, y\n",
        "    else:\n",
        "      return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "# Model\n",
        "Feel free to modify the structure of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bg-GRd7ywdrL"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # TODO: apply batch normalization and dropout for strong baseline.\n",
        "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
        "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim, affine=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.25)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock(input_dim, hidden_dim),\n",
        "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameters"
      ],
      "metadata": {
        "id": "TlIq8JeqvvHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data prarameters\n",
        "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
        "concat_nframes = 11   # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "train_ratio = 0.75   # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# training parameters\n",
        "seed = 1213          # random seed\n",
        "batch_size = 512        # batch size\n",
        "num_epoch = 70         # the number of training epoch\n",
        "learning_rate = 1e-4      # learning rate\n",
        "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "\n",
        "# model parameters\n",
        "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
        "input_dim = 39 * concat_nframes  # the input dim of the model, you should not change the value\n",
        "hidden_layers = 8          # the number of hidden layers\n",
        "hidden_dim = 1024           # the hidden dim"
      ],
      "metadata": {
        "id": "iIHn79Iav1ri"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "IIUFRgG5yoDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "\n",
        "same_seeds(seed)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "c1zI3v5jyrDn",
        "outputId": "e81124e4-32d6-40ef-f24e-707f2a7a528e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n",
            "[Dataset] - # phone classes: 41, number of utterances for train: 2571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-4-d5bf7855f377>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\n",
            "2571it [00:12, 198.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] train set\n",
            "torch.Size([1588590, 429])\n",
            "torch.Size([1588590])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "858it [00:01, 470.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] val set\n",
            "torch.Size([528204, 429])\n",
            "torch.Size([528204])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "pwWH1KIqzxEr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CdMWsBs7zzNs",
        "outputId": "60a7744f-dd57-4b3e-e5b0-9a62dde0f422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:47<00:00, 65.02it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 159.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/070] Train Acc: 0.51217 Loss: 1.64501 | Val Acc: 0.60793 loss: 1.26958\n",
            "saving model with acc 0.60793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.06it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[002/070] Train Acc: 0.58933 Loss: 1.33410 | Val Acc: 0.63770 loss: 1.16018\n",
            "saving model with acc 0.63770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.08it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 156.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[003/070] Train Acc: 0.61188 Loss: 1.25094 | Val Acc: 0.65207 loss: 1.10715\n",
            "saving model with acc 0.65207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.68it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[004/070] Train Acc: 0.62599 Loss: 1.20004 | Val Acc: 0.66103 loss: 1.07527\n",
            "saving model with acc 0.66103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.93it/s]\n",
            "100%|██████████| 1032/1032 [00:08<00:00, 126.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[005/070] Train Acc: 0.63579 Loss: 1.16364 | Val Acc: 0.66772 loss: 1.04773\n",
            "saving model with acc 0.66772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.54it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 146.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[006/070] Train Acc: 0.64398 Loss: 1.13542 | Val Acc: 0.67409 loss: 1.02866\n",
            "saving model with acc 0.67409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.02it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 159.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[007/070] Train Acc: 0.64987 Loss: 1.11355 | Val Acc: 0.67765 loss: 1.01609\n",
            "saving model with acc 0.67765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.03it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[008/070] Train Acc: 0.65511 Loss: 1.09477 | Val Acc: 0.68270 loss: 0.99892\n",
            "saving model with acc 0.68270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.16it/s]\n",
            "100%|██████████| 1032/1032 [00:09<00:00, 105.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[009/070] Train Acc: 0.65938 Loss: 1.07900 | Val Acc: 0.68628 loss: 0.98699\n",
            "saving model with acc 0.68628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.87it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[010/070] Train Acc: 0.66333 Loss: 1.06467 | Val Acc: 0.68707 loss: 0.98181\n",
            "saving model with acc 0.68707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.63it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 147.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[011/070] Train Acc: 0.66730 Loss: 1.05139 | Val Acc: 0.68966 loss: 0.97509\n",
            "saving model with acc 0.68966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:47<00:00, 65.48it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 158.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[012/070] Train Acc: 0.67051 Loss: 1.04032 | Val Acc: 0.69143 loss: 0.96831\n",
            "saving model with acc 0.69143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.04it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 143.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[013/070] Train Acc: 0.67351 Loss: 1.03035 | Val Acc: 0.69482 loss: 0.95530\n",
            "saving model with acc 0.69482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.16it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 149.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[014/070] Train Acc: 0.67616 Loss: 1.02034 | Val Acc: 0.69599 loss: 0.95235\n",
            "saving model with acc 0.69599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.05it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[015/070] Train Acc: 0.67789 Loss: 1.01258 | Val Acc: 0.69829 loss: 0.94439\n",
            "saving model with acc 0.69829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.10it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 146.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[016/070] Train Acc: 0.68058 Loss: 1.00386 | Val Acc: 0.69838 loss: 0.94651\n",
            "saving model with acc 0.69838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.39it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 146.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[017/070] Train Acc: 0.68240 Loss: 0.99737 | Val Acc: 0.70040 loss: 0.93881\n",
            "saving model with acc 0.70040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.50it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[018/070] Train Acc: 0.68426 Loss: 0.99053 | Val Acc: 0.70237 loss: 0.93349\n",
            "saving model with acc 0.70237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.24it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 148.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[019/070] Train Acc: 0.68585 Loss: 0.98417 | Val Acc: 0.70303 loss: 0.93043\n",
            "saving model with acc 0.70303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:45<00:00, 67.54it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[020/070] Train Acc: 0.68727 Loss: 0.97890 | Val Acc: 0.70388 loss: 0.92718\n",
            "saving model with acc 0.70388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.07it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[021/070] Train Acc: 0.68930 Loss: 0.97289 | Val Acc: 0.70445 loss: 0.92688\n",
            "saving model with acc 0.70445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.00it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 148.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[022/070] Train Acc: 0.69057 Loss: 0.96738 | Val Acc: 0.70489 loss: 0.92303\n",
            "saving model with acc 0.70489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.34it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[023/070] Train Acc: 0.69209 Loss: 0.96295 | Val Acc: 0.70603 loss: 0.91885\n",
            "saving model with acc 0.70603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.31it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[024/070] Train Acc: 0.69340 Loss: 0.95793 | Val Acc: 0.70730 loss: 0.91568\n",
            "saving model with acc 0.70730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.01it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 148.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[025/070] Train Acc: 0.69440 Loss: 0.95398 | Val Acc: 0.70674 loss: 0.91576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.91it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[026/070] Train Acc: 0.69596 Loss: 0.94845 | Val Acc: 0.70758 loss: 0.91646\n",
            "saving model with acc 0.70758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.99it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 161.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[027/070] Train Acc: 0.69710 Loss: 0.94507 | Val Acc: 0.70856 loss: 0.91148\n",
            "saving model with acc 0.70856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.08it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 146.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[028/070] Train Acc: 0.69799 Loss: 0.94094 | Val Acc: 0.70977 loss: 0.90951\n",
            "saving model with acc 0.70977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.41it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 130.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[029/070] Train Acc: 0.69909 Loss: 0.93705 | Val Acc: 0.71072 loss: 0.90604\n",
            "saving model with acc 0.71072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.91it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 158.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[030/070] Train Acc: 0.70038 Loss: 0.93303 | Val Acc: 0.71131 loss: 0.90400\n",
            "saving model with acc 0.71131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.11it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[031/070] Train Acc: 0.70063 Loss: 0.93029 | Val Acc: 0.71076 loss: 0.90394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:45<00:00, 67.46it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[032/070] Train Acc: 0.70210 Loss: 0.92644 | Val Acc: 0.71117 loss: 0.90444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.66it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 162.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[033/070] Train Acc: 0.70340 Loss: 0.92296 | Val Acc: 0.71146 loss: 0.90368\n",
            "saving model with acc 0.71146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.03it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 143.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[034/070] Train Acc: 0.70351 Loss: 0.92129 | Val Acc: 0.71197 loss: 0.90335\n",
            "saving model with acc 0.71197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:45<00:00, 67.46it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[035/070] Train Acc: 0.70455 Loss: 0.91726 | Val Acc: 0.71315 loss: 0.89965\n",
            "saving model with acc 0.71315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.45it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[036/070] Train Acc: 0.70541 Loss: 0.91425 | Val Acc: 0.71296 loss: 0.89676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.05it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[037/070] Train Acc: 0.70628 Loss: 0.91171 | Val Acc: 0.71440 loss: 0.89588\n",
            "saving model with acc 0.71440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.33it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 148.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[038/070] Train Acc: 0.70707 Loss: 0.90931 | Val Acc: 0.71385 loss: 0.89623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.25it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[039/070] Train Acc: 0.70777 Loss: 0.90534 | Val Acc: 0.71513 loss: 0.89295\n",
            "saving model with acc 0.71513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.14it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 131.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[040/070] Train Acc: 0.70818 Loss: 0.90376 | Val Acc: 0.71530 loss: 0.89382\n",
            "saving model with acc 0.71530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.92it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 153.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[041/070] Train Acc: 0.70859 Loss: 0.90178 | Val Acc: 0.71433 loss: 0.89330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.95it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 160.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[042/070] Train Acc: 0.70995 Loss: 0.89869 | Val Acc: 0.71621 loss: 0.89183\n",
            "saving model with acc 0.71621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.85it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[043/070] Train Acc: 0.71049 Loss: 0.89667 | Val Acc: 0.71582 loss: 0.88922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.99it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 150.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[044/070] Train Acc: 0.71070 Loss: 0.89404 | Val Acc: 0.71598 loss: 0.89063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.90it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 159.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[045/070] Train Acc: 0.71113 Loss: 0.89259 | Val Acc: 0.71648 loss: 0.88750\n",
            "saving model with acc 0.71648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.98it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[046/070] Train Acc: 0.71240 Loss: 0.88980 | Val Acc: 0.71647 loss: 0.88984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.12it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 151.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[047/070] Train Acc: 0.71285 Loss: 0.88738 | Val Acc: 0.71719 loss: 0.88844\n",
            "saving model with acc 0.71719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.10it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 161.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[048/070] Train Acc: 0.71300 Loss: 0.88618 | Val Acc: 0.71643 loss: 0.88805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.14it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[049/070] Train Acc: 0.71392 Loss: 0.88415 | Val Acc: 0.71799 loss: 0.88710\n",
            "saving model with acc 0.71799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:45<00:00, 67.56it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 143.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[050/070] Train Acc: 0.71476 Loss: 0.88129 | Val Acc: 0.71747 loss: 0.88616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.99it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 161.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[051/070] Train Acc: 0.71483 Loss: 0.88050 | Val Acc: 0.71828 loss: 0.88402\n",
            "saving model with acc 0.71828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.03it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 146.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[052/070] Train Acc: 0.71511 Loss: 0.87789 | Val Acc: 0.71851 loss: 0.88212\n",
            "saving model with acc 0.71851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:45<00:00, 67.55it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[053/070] Train Acc: 0.71611 Loss: 0.87671 | Val Acc: 0.71786 loss: 0.88455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.08it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 161.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[054/070] Train Acc: 0.71685 Loss: 0.87435 | Val Acc: 0.71838 loss: 0.88256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.68it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 147.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[055/070] Train Acc: 0.71686 Loss: 0.87393 | Val Acc: 0.71895 loss: 0.88261\n",
            "saving model with acc 0.71895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:45<00:00, 67.84it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 147.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[056/070] Train Acc: 0.71774 Loss: 0.87082 | Val Acc: 0.71874 loss: 0.88289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.32it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 162.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[057/070] Train Acc: 0.71787 Loss: 0.87000 | Val Acc: 0.71913 loss: 0.88192\n",
            "saving model with acc 0.71913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.43it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 149.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[058/070] Train Acc: 0.71846 Loss: 0.86744 | Val Acc: 0.71969 loss: 0.87969\n",
            "saving model with acc 0.71969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.32it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[059/070] Train Acc: 0.71885 Loss: 0.86579 | Val Acc: 0.71828 loss: 0.88446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.09it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 159.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[060/070] Train Acc: 0.71959 Loss: 0.86458 | Val Acc: 0.72012 loss: 0.87946\n",
            "saving model with acc 0.72012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.11it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 154.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[061/070] Train Acc: 0.71955 Loss: 0.86287 | Val Acc: 0.72048 loss: 0.88161\n",
            "saving model with acc 0.72048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.39it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 143.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[062/070] Train Acc: 0.72056 Loss: 0.86153 | Val Acc: 0.71944 loss: 0.88025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.12it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 155.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[063/070] Train Acc: 0.72032 Loss: 0.86078 | Val Acc: 0.72044 loss: 0.88121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.10it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 161.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[064/070] Train Acc: 0.72100 Loss: 0.85796 | Val Acc: 0.72024 loss: 0.87860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.07it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[065/070] Train Acc: 0.72157 Loss: 0.85713 | Val Acc: 0.72106 loss: 0.87865\n",
            "saving model with acc 0.72106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.39it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 149.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[066/070] Train Acc: 0.72205 Loss: 0.85622 | Val Acc: 0.72092 loss: 0.87705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.11it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 161.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[067/070] Train Acc: 0.72199 Loss: 0.85483 | Val Acc: 0.72111 loss: 0.87905\n",
            "saving model with acc 0.72111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.10it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 145.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[068/070] Train Acc: 0.72233 Loss: 0.85312 | Val Acc: 0.72107 loss: 0.87829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 67.38it/s]\n",
            "100%|██████████| 1032/1032 [00:07<00:00, 144.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[069/070] Train Acc: 0.72260 Loss: 0.85140 | Val Acc: 0.72173 loss: 0.87612\n",
            "saving model with acc 0.72173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3103/3103 [00:46<00:00, 66.22it/s]\n",
            "100%|██████████| 1032/1032 [00:06<00:00, 158.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[070/070] Train Acc: 0.72327 Loss: 0.85058 | Val Acc: 0.72203 loss: 0.87558\n",
            "saving model with acc 0.72203\n"
          ]
        }
      ],
      "source": [
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # validation\n",
        "    model.eval() # set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(val_loader)):\n",
        "            features, labels = batch\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(features)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, val_pred = torch.max(outputs, 1)\n",
        "            val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
        "\n",
        "    # if the model improves, save a checkpoint at this epoch\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ab33MxosWLmG",
        "outputId": "dcb49ebd-e13e-4cdd-879e-86c0d54a836b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "del train_set, val_set\n",
        "del train_loader, val_loader\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "# Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VOG1Ou0PGrhc",
        "outputId": "1b0b7d81-69b0-4e9b-c4f1-fe83045c1ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-4-d5bf7855f377>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\n",
            "857it [00:01, 558.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] test set\n",
            "torch.Size([527364, 429])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ay0Fu8Ovkdad",
        "outputId": "8d8ef732-bc88-452b-df93-8c913804b726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-f7b7612de35f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "84HU5GGjPqR0",
        "outputId": "c2e13295-e7f6-4fc9-ebcb-30f07efe9ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1031/1031 [00:05<00:00, 198.02it/s]\n"
          ]
        }
      ],
      "source": [
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        features = features.to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}